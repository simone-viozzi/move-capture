\documentclass[10pt,a4paper]{article}

\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage[left=1cm,right=1cm,top=1cm,bottom=2cm]{geometry}

\usepackage{txfonts}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{titlesec}
\setcounter{secnumdepth}{4}
\titleformat{\paragraph}{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

%per le immagini
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{wrapfig}

%per i link
\usepackage{hyperref} 

%%%%%%%% per il codice c++
\usepackage{textcomp}
\usepackage{listings}          % for creating language style
\usepackage{listingsutf8}
\input{arduinoLanguage.tex}    % adds the arduino language listing
\definecolor{commentgreen}{RGB}{2,112,10}
\definecolor{eminence}{RGB}{108,48,130}
\definecolor{weborange}{RGB}{255,165,0}
\definecolor{frenchplum}{RGB}{129,20,83}


%% Define an Arduino style fore use later %%
\lstdefinestyle{myArduino}{
  language=Arduino,
    %% Add other words needing highlighting below %%
    morekeywords=[1]{},                  % [1] -> dark green
    morekeywords=[2]{FILE_WRITE},        % [2] -> light blue
    morekeywords=[3]{SD, File},          % [3] -> bold orange
    morekeywords=[4]{open, exists, write, SoftwareSerial},      % [4] -> orange
    frame=tb,    
    inputencoding=utf8,
    extendedchars=true,
    literate={è}{{\`{e}}}{1},
    breaklines=true,  
}

\lstdefinestyle{mycpp}{
    language=C++,
    inputencoding=utf8,
    extendedchars=true,
    literate={è}{{\`{e}}}{1},
    %escapeinside={(*******}{*******)}
    escapechar=\£,
    %escapeinside=~~,
    frame=tb,
    tabsize=2,
    mathescape=false,
    breaklines=true,                    % wordwrapping
    postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},         
    basicstyle=\fontsize{9}{11}\ttfamily,
    backgroundcolor=\color{light-gray},
    xleftmargin=.25in,
    showstringspaces=false,
    numbers=left,                    
    numbersep=5pt,                   
    %numberstyle=\color{arduinoGrey},    
    %stepnumber=2, 
    %upquote=true,
    commentstyle=\color{commentgreen},
    keywordstyle=\color{eminence},
    stringstyle=\color{red},
    basicstyle=\small\ttfamily, % basic font setting
    emph={int,char,double,float,unsigned,void,bool},
    emphstyle={\color{blue}},
    % keyword highlighting
    classoffset=1, % starting new class
    otherkeywords={>,<,.,;,-,!,=,~},
    morekeywords={>,<,.,;,-,!,=,~},
    keywordstyle=\color{weborange},
    classoffset=0,
}

\lstdefinestyle{mycuda}{
    language=C++,
    inputencoding=utf8,
    extendedchars=true,
     literate=
    {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
    {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
    {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
    {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
    {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
    {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
    {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
    {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
    {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
    {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
    {€}{{\EUR}}1 {£}{{\pounds}}1,
    %escapeinside={(*******}{*******)}
    escapechar=\£,
    %escapeinside=~~,
    frame=tb,
    tabsize=2,
    mathescape=false,
    breaklines=true,                    % wordwrapping
    postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},         
    basicstyle=\fontsize{9}{11}\ttfamily,
    backgroundcolor=\color{light-gray},
    xleftmargin=.25in,
    showstringspaces=false,
    numbers=left,                    
    numbersep=5pt,                   
    %numberstyle=\color{arduinoGrey},    
    %stepnumber=2, 
    %upquote=true,
    commentstyle=\color{commentgreen},
    keywordstyle=\color{eminence},
    stringstyle=\color{red},
    basicstyle=\small\ttfamily, % basic font setting
    emph={int,char,double,float,unsigned,void,bool},
    emphstyle={\color{blue}},
    morekeywords = [2]{cudaMalloc, cudaFree,
        __global__, __shared__, __device__, __host__,
        __syncthreads},
    keywordstyle=[2]\color{magenta},
    % keyword highlighting
    classoffset=1, % starting new class
    otherkeywords={>,<,.,;,-,!,=,~},
    morekeywords=[3]{>,<,.,;,-,!,=,~zz},
    keywordstyle=[3]\color{weborange},
    classoffset=0,
}

\lstdefinestyle{myoutput}
{
    inputencoding=utf8,
    extendedchars=true,
    literate={è}{{\`{e}}}{1},
    tabsize=2,
    frame=tb,
    breaklines=true,                    % wordwrapping
    postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},         
    basicstyle=\fontsize{9}{11}\ttfamily,
    backgroundcolor=\color{light-gray},
    xleftmargin=.25in,
    showstringspaces=false,
    numbers=left,                    
    numbersep=5pt, 
}
%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{siunitx} %pacchetto per le unita' di misura

%%%%%%%%%%%%%%%%%%%%%% per i flowchart
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usepgflibrary{shapes.symbols}
\usetikzlibrary{shapes.multipart}

\tikzset{%
  >={Latex[width=2mm,length=2mm]},
  % Specifications for style of nodes:
            rect/.style = {rectangle, rounded corners, draw=black,
                           minimum width=4cm, minimum height=1cm,
                           text centered, font=\sffamily},
           round/.style = {ellipse, draw, draw=black,
                           minimum width=4cm, minimum height=1cm,
                           text centered, font=\sffamily},
       smallrect/.style = {rectangle, rounded corners, draw=black,
                           minimum width=2cm, minimum height=1cm,
                           text centered, font=\sffamily},
 smallrectsplit4/.style = {rectangle split, rectangle split parts=4, 
	                       rectangle split part fill={green!30, none, none, none},
	                       align=center,
	                       rounded corners, draw=black,
                           minimum width=2cm, minimum height=1cm,
                           text centered, font=\sffamily},
}

%\tikzset{%
%    >={Latex[width=2mm,length=2mm]},
%      % Specifications for style of nodes:
%         declare/.style = {trapezium,draw=black, minimum width=4cm, minimum height=1cm, 
%                                trapezium right angle=-70, trapezium left angle=70,
%                                minimum width=4cm, minimum height=1cm,
%                                text centered, font=\sffamily},
%           start/.style = {ellipse, draw, draw=black, minimum width=4cm, 
%                                minimum height=1cm, text centered, font=\sffamily},
%            cond/.style = {diamond, aspect=2, draw, draw=black,
%                                minimum width=4cm, minimum height=1cm,
%                                text centered, font=\sffamily},
%            rect/.style = {rectangle, draw, draw=black,
%                                minimum width=4cm, minimum height=1cm,
%                                text centered, font=\sffamily},
%}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 

\pagenumbering{arabic}
\pagestyle{plain}

% per non farlo anadre a capo ovunque 
% va in conflitto con quello che lo fa andare a capo nel codice quindi attenzione <--------
%\usepackage[none]{hyphenat}


% per togliere gli ident all'inizio dei paragrafi
\setlength{\parindent}{0pt}






\begin{document}

\subsection{OpenLearn documentazione}
Questa parte della relazione è dedicata all'illustrazione e al commento della struttura e delle parti principali  del componente principale del progetto, la libreria di machine learning sviluppata per la creazione, l'addestramento e l'utilizzo dei modelli neuronali.
La libreria è stata sviluppata per un utilizzo general-purpose, quindi non finalizzata alla risoluzione dello specifico problema proposto, il quale è stato utilizzato per testare la risposta di varie strutture neurali alla risoluzione di un problema con soluzione nota ma attraverso l'elaborazione di dati di ingresso fortemente affetti da rumore.
\\
Nella documentazione verranno mostrate soltanto le caratteristiche principali della libreria, le classi, le strutture e i metodi più importanti effettivamente utilizzati benche la libreria ne presenti altri predisposti per future revisioni ed espansioni.

\subsubsection{Le librerie importate}
Le prime librerie importate sono le librerie per l'utilizzo del linguaggio C/CUDA, proprietario di Nvidia, per la programmazione delle schede della stessa azienda.
\begin{lstlisting}[style=mycuda, caption=librerie cuda, captionpos=b]
//////////////CUDA INCLUDES///////////////
#include "cuda.h"
#include "cuda_runtime.h"
#include <device_functions.h>
#include "device_launch_parameters.h"

\end{lstlisting}
Sono state importate poi diverse librerie standard del linguaggio C++, principalmente:\\
la classe vector è stata usata per l'incapsulamento e la manipolazione dei dati.\\
le classi *stream sono state utilizzate per il salvataggio e il caricamento dei modelli su file di testo.\\
la libreria windows per l'utilizzo delle funzioni di timing ad alta precisione.\\

\begin{lstlisting}[style=mycuda, caption=librerie STD, captionpos=b]

#include "stdafx.h"
#include <iostream>
#include <stdio.h>
#include <fstream>
#include <sstream>
#include <string>
#include <windows.h>
#include <limits>
#include <math.h>
#include <vector>
#include <list>
#include <time.h>
#include <algorithm>
#include <assert.h>

\end{lstlisting}

\subsubsection{classi di creazione e addestramento modelli su CPU}
Di seguito sono illustrate le strutture che formano lo scheletro dei modelli, tali strutture sono state pensate per essere completamente modulari e per permettere la realizzazione di diversi modelli, dalle più semplici feed-forward, alle più complesse ricorrenti. Tale approccio permette la massima maneggevolezza della struttura sacrificando l'efficienza che deriva da una computazione matriciale.
\begin{lstlisting}[style=mycuda, caption=struct strutturali del modello, captionpos=b]
//prototipo struttura neuron
struct Neuron; 
//dichiarazione puntatore a neuron
typedef Neuron *ptNeuron;

//La struttura arc, presente in array nella struttura Neuron
//conserva i dati delle connessioni e il puntatore alla struttura Neuron puntata 
struct arc {
	ptNeuron target = nullptr;
	float weight = 0;
	float oldDelta = 0;
	//bool enabled = true;
};

//La struttura interArc è stata creata per l'addestramento MLP supportato da un rete ricorrente
//fornisce un arco di interconnessione tra i neuroni di 2 reti
struct interArc {
	ptNeuron target = nullptr;
	ptNeuron base = nullptr;
};

//La struttura Neuron è l'unità base delle strutture delle reti e ne conserva tutti i parametri
struct Neuron {
	//OutArcs è il vettore di connessioni ai neuroni degli strati successivi 
	// to inizialize: = new vector<arc>(10);
	vector<arc> OutArcs; 
	// numero di archi in uscita
	u_int numOutArcs = 0; 
	//numero di archi in ingresso
	u_int numInArcs = 0; 
	//indice riga del neurone	
	u_int layer = 0; 
	//indice della colonna del neurone
	u_int column = 0; 
	//peso del bayes
	float bayes = 0.01f; 
	//ultima variazione del peso
	float oldBayesDelta = 0; 
	// vettore delle interconnessioni temporali
	//vector<float> timeBayes; 
	// vettore contenente la percentuale di influenza relativa ad ogni input
	vector<float> influenceInput; 
	// vettore contenente la percentuale di influenza relativa all'errore  retropropagato da ogni output
	vector<float> influenceOutput; 
	//potenziale attuale del neurone
	float output = 0; 
	//somma in valore assoluto degli input del neurone
	float absOutSum = 0; 
	//somma in valore assoluto delle variazioni dei pesi
	float absDeltaSum = 0; 
	//errore di retropropagazione
	float BPerr = 0; 
	//ogni neurone è contraddistinto da un indice unico che si riferisce alla sua posizione
	int neurIdx = 0; 
};

//La struct Layer è stata realizzata per contenere un layer di neuroni
struct Layer {
	vector<Neuron> Neurons;
	u_int numNeurons = 0;
};

//Omap conserva la scala di conversione tra l'output
struct Omap {
	float maxValue = 1;
	float minValue = 0;
};

// struttura necessaria per l'inserimento di un nuovo neurone
struct conMap { 
	u_int startLyr;
	u_int startCol;
	u_int arcRef;
	u_int targetLyr;
	u_int targetCol;
};

//conserva una serie temporale prima dell'accomulazione in una struct Dataset 
struct timeSeries {
	list<float> evento;
};

//struttura contenente il singolo esempio
struct example {
	vector<float> input;
	vector<float> Doutput;
};

//Struttura contenente l'intero Dataset di una rete
struct Dataset {
	vector<example> trainingSet; // vettore esempi del training set
	vector<example> validationSet; // vettore esempi del validation set
	float triningErr = 0; //percentuale di errore training set
	float validationErr = 0; //percentuale di errore validation set
};

\end{lstlisting}

La classe DatasetCore è stata realizzata per permettere l'estrazione dei dataset da vari formati, riportandoli nello standard di utilizzato dalle classi che li utilizzano per effettuare gli addestramenti.
\begin{lstlisting}[style=mycuda, caption=class DatasetCore, captionpos=b]
class DatasetCore {
public:
	// lista dei dataset
	list<Dataset> Datasets; 
	
	// costruttore DatasetCore
	DatasetCore() { ... }
	
	//////////////////////MANIPOLAZIONE DATASET////////////////////////////////////
	//funzione che consente la lettura di serie temporali da csv e le ristruttura in un dataset
	void readTimeSeriesCsv(string filename, int outStep, int inEx, float trainingPerc) { ... }
	
	//estrae un dataset dalla lista interna della classe, la parte training se il flag e true
	// o la parte validation se il flag è false
	vector<example> getDataset(int n, bool training = true) { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	//////////////////////////ALTRE FUNZIONI//////////////////////////////////////////////
	//metodo interno per contare le righe di un file
	int coutnRow(string filename) { ... }
\end{lstlisting}

La classe network fornisce le variabili e i metodi generali che la maggior parte degli oggetti rete utilizza. 
\begin{lstlisting}[style=mycuda, caption=class Network, captionpos=b]
class Network {

public:
	// vettore di struct layer
	vector<Layer> Layers; 
	// vettore di esempi per l'apprendimento
	vector<example> examples; 
	// vettore contenente i valori di rimappatura del'output della rete
	vector<Omap> map; 

	// nome del file contenente la struttura della rete
	string genoma = ""; 
	// Layer nella rete compresi strato input e strato output
	u_int nLayers = 0; 
	// numero totale neuroni nella rete
	u_int nNeurons = 0; 
	//numero totale di tutti gli archi presenti nella rete
	u_int nArc = 0;
	
	//costruttore
	Network(string filename) {
		genoma = filename;
	}

	////////////////FUNZIONE COSTRUZIONE RETE DA FILE////////////////////////////////////
	//dato il nome del file contenete la struttura carica l'oggetto corrispondente
	void getNetParams() { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	////////////////////FUNZIONE COSTRUZIONE DATASET DA FILE//////////////////////////////
	//dato il file contenente un dataset prestrutturato correttamente lo carica nel modello
	void getDataset(string filename) { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	////////////////////SALVA RETE SU FILE////////////////////////////////////////////////
	//salva la rete sul file specificato
	void saveNet(string filename = "") { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	////////////////////////SALVA DATASET SU FILE/////////////////////////////////////////
	//salva il datset sul file specificato
	void saveDataset(string filename) { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	////////////////////// FUNZIONI MODIFICA RETE/////////////////////////////////////////
	//elimina un arco dati i parametri diriferimento
	void deleteArc(int Nlayer, int Ncolumn, int targetLayer, int targetColumn) { ... }
	
	//elimina un neurone, compresi tutti gli archi ad esso connesso
	void deleteNeuron(int Nlayer, int Ncolumn) { ... }
	
	//aggiunge un arco dati i riferimenti al neurone di partenza e di arrivo
	void addArc(int Nlayer, int Ncolumn, int targetLayer, int targetColumn) { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	/////////////////////////FUNZIONI VARIE///////////////////////////////////////////////
	float DsigOut(int Layer, int Neuron) { ... }
	float sigmoid(float x) { return 1 / (1 + exp(-x)); } // Sigmoide
	float logit(float x) { return log(x / (1 - x)); } // funzione sigmoide inversa 
	float gaussian(float x, float mu, float var) { ... }
	void WeightsStamp(string mode = "a") { ... }
		//m - stampa le medie dei pesi di ogni layer
		//a - stampa tutti i pesi della rete con alcuni parametri di apprendimento
		//w - stampa tutti i pesi con il riferimento riga colonna al target
		//fc - stampa le medie dei gruppi di pesi tra due layer 	
		
	//funzione sigmoide	
	void sigLayer(int lyr) { ... }
	
	//applica il bayes all'output di ogni neurone del dato layer
	void bayesLayer(int lyr, bool absSum = false) { ... }
	
	// esegue il reset del potenziale di tutti i neuroni della rete
	void resetPotential() { ... }
	
	// esegue il reset della sommatoria di ogni input in valore assoluto di ogni neurone
	void resetAbsSumPotenzial() { ... }
	
	// esegue il reset della sommatoria di ogni input in valore assoluto di ogni neurone
	void resetAbsSumDelta() { ... }
	
	// esegue il reset dell'errore retropropagato in ogni neurone
	void resetBPerr() { ...}
	
	//resetta il valore ID nei neuroni di una rete (necessario per modifiche strutturali)	
	void resetNeuronsID() { ... }
	
	// salva su vettore i riferimenti numerici delle connesioni verso il layer specificato
	vector<conMap> saveConsTowardsLyr(int Layer) { ... }
	
	// ricarica i riferimenti numerici delle connesioni verso il layer specificato	
	void loadConsTowardsLyr(vector<conMap> con) { ... } 
	
	//elimina il contenuto l'oggetto dataset dell'oggetto rete
	void ClearDataset() { ... }
	
	//generazione di una serie storica del seno (DEBUG)
	void genTestDataset(int nExe, int nIn, int nOut, float step, int type, float offset) { ... }
	
	//esegue il settaggio della mappatura di output dell'oggetto
	void setNetMap(float max, float min) { ... }
	
	//restituisce il valore normalizzato dell'output della rete
	float reverseMap(int neur, float val) { ... }
	
	// crea un vettore di n elementi successivi e li disordina
	// creazione di una tabella di accesso casuale per un secondo vettore
	vector<u_int> casualVector(int in, int start = 0) { ... }
		
	//esegue il mescolamento degli elementi all'interno di un oggetto vector 
	/*vector<T, A>*/
	template<typename T, typename A>
	void shackeVector(vector<T, A> const& vec) { ... }
		
	//ricalcola gli ID dei neuroni dopo il reset (da eseguire dopo delle modifiche strutturali)	
	void refreshNeurIdx() { ... }
	
	//applica all'intero dataset un valore di offset
	void datasetOffset(float offset) { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	///////////////////////ACCESSO A VARIABILI PRIVATE////////////////////////////////////
	int numLayers() { ... }
	int numNeurons(int Layer) { ... }
	int numCon(int Layer, int Neuron) { ... }
	int numInCon(int Layer, int Neuron) { ... }
	int getConTargetLyr(int Layer, int Neuron, int Arc) { ... }
	int getConTargetCol(int Layer, int Neuron, int Arc) { ... }
	float getWeight(int Layer, int Neuron, int Arc) { ... }
	float getDeltaWeight(int Layer, int Neuron, int Arc) { ... }
	float getOutput(int Layer, int Neuron) { ... }
	float getBPerr(int Layer, int Neuron) { ... }
	ptNeuron getTarget(int Layer, int Neuron) { ... }
	ptNeuron getConTarget(int Layer, int Neuron, int Conn) { ... }
	int getOutConTargetID(ptNeuron base, ptNeuron target) { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	/////////////////////////WINDOWS HIGH PRECISION TIMING////////////////////////////////////
	BOOL WINAPI QueryPerformanceCounter(_Out_ LARGE_INTEGER *lpPerformanceCount);
	BOOL WINAPI QueryPerformanceFrequency(_Out_ LARGE_INTEGER *lpFrequency);
	inline long long PerformanceCounter() noexcept
	{...}
	inline long long PerformanceFrequency() noexcept
	{...}
	//////////////////////////////////////////////////////////////////////////////////////
};

\end{lstlisting}

La classe MLP (multi-layer perceptron) figlia della classe Network completa il corredo della madre con tutta una serie di strumenti e variabili che supporta l'addestramento e l'utilizzo di questa tipologia di reti.
\begin{lstlisting}[style=mycuda, caption=class MLP, captionpos=b]

class MLP : public Network {

public:
	// tempo di esecuzione medio in millisecondi
	float NetPerformance = 0; 
	
	//errore percentuale medio associato alla rete
	float NetErrPercent = 0; 
	
	//costruttore
	MLP(string filename) :Network(filename) {};

	/////////////////////FUNZIONI CREAZIONE RETE/////////////////////////////////////////
	//permette la costruzione rapida di una rete MLP quadrata con dimensioni date
	void qubeNet(int Nlayers, int Ncolumns, int input, int output, bool c, float initValue = 0.01f) { ... }
	
	//CREAZIONE RETE QUADRATA COMPLETAMENTE CONNESSA
	//permette la costruzione di una rete MLP quadrata con dimensioni date in cui ogni neurone
	//è connesso a tutti i neuroni di tutti gli strati successivi.
	//(a parità di neuroni tale modello è più pesante ma tipicamente ha un aprrendimento più rapido)
	void qubeNetFC(int Nlayers, int Ncolumns, int input, int output, bool c, float initValue = 0.01f) { ... }
	
	//CREAZIONE RETE CUSTOM
	//permette la creazione di una rete MLP con la larghezza di ogni layer variabile
	//indicando tali larghezze con un apposito vettore dato come argomento
	void customNet(int Nlayers, vector<int> Ncolumns, float conFill) { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	/////////////////////STIMOLAZIONE RETE////////////////////////////////////////////////
	//procedura di propagazione dell'informazione
	//dati i riferimenti al vettore contenete gli input e ad un vettore di output esegue
	//il processamento degli input e carica l'output derivante sul vettore indicato
	void inputNet(vector<float> &input, vector<float> &output) { ... }
	
	//esegue una propagazione dell'informazione salvando lo storico di propagazione degli input
	//tale funzione viene utilizzata per l'apprendiment strutturale
	void inputNetProfiler(vector<float> &input, vector<float> &output) { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	////////////////////////FUNZIONI DI ADDESTRAMENTO MLP/////////////////////////////////
	//Algoritmo di addestramento Back-propagation su tutto il dataset caricato
	void BP(int iter, float eps, float beta, float ErrPercent) { ... }
	
	//esecuzione del backpropagation per un solo esempio 
	//specificando il particolare esempio
	void oneBP(float eps, float beta, example e) { ... }
	//////////////////////////////////////////////////////////////////////////////////////
	
	///////////////////////ALTRE FUNZIONI MLP/////////////////////////////////////////////
	//inizializza i vettori di benchmark presenti nei neuroni per l'apprendimento strutturale
	void initVectorsProfiler() { ... }
	
	//resetta a zero tutti i vettori di profilazione esclusi layer input e output
	void resetVectorsProfiler(bool inInfl, bool outInfl) { ... }
	
	//stampa a schermo l'influenza degli input per ogni uscita
	void stampInputInfluences(bool all = false) { ... }
	
	//stampa a schermo l'influenza degli errori degli output per ogni ingresso
	void stampOutputErrorPropagation(bool all = false) { ... }
	
	//dal riferimento al nodo target e dall'indice del vettore restituisce il puntatore al neurone base
	ptNeuron basePosfromtarget(ptNeuron target, int k) { ... }
	
	//dato un neurone e l'indice di un suo arco restituisce l'indice di quella connessione all'interno del 				//vettore influenceInput all'interno del neurone target
	int idBaseConReftoTargetInfl(ptNeuron base, int arc) { ... }
	//////////////////////////////////////////////////////////////////////////////////////

};

\end{lstlisting}
\clearpage
\subsubsection{altre classi non utilizzate nel progetto}
Le seguenti classi sono state iniziate e verranno completate in futuro, La classe Hopfield supporta (ancora in parte) la creazione l'addetramento e l'utilizzo delle reti ricorrenti, ovvere reti con connessioni tra i neuroni che si retropropagano, ovvero che portano potenziali di uscita di neuroni nello strato output e hidden al tempo (t), ad altri neuroni nel tempo (t+1).\\
La classe structural learning è stata realizzata e testa, ma presenta notevoli inefficienze che non permettono di utilizzarla in questa forma su modelli di grandi dimensioni, tale classe comunque è stata realizzata per effettuare un addestramento che mira a modificare la struttura della rete durante l'addestramento eliminando le connessioni che risultano essere mediamente quelle che persistono nell'introduzione di errore rispetto alle altre.
\begin{lstlisting}[style=mycuda, caption=altre classi, captionpos=b]
class Hopfield : public Network { ... };

class StructuralLearning { ... };
\end{lstlisting}

\subsubsection{Classi e kernel per l'interfacciamento con la GPU}
In questa sezione sono stati implementati i kernel della GPU, ovvero le funzioni scritte in C/CUDA, che vengono eseguite sulla scheda grafica. tali funzioni sono contraddistinte dalla keyword \_\_global\_\_,  e richiedono come argomenti gli indirizzi di memoria corrispondenti ai dati precaricati sulla global memory della GPU.
Il richiamo dei kernel dal codice C++ richiedono la sintassi speciale: \\
\textbf{CUDAapplyWeightCorrections <<<numOfBlocksA, ThxBlock >>> (...);} \\
si vede infatti la sequenza di caratteri <<<A,B>>> dove A è il numero di blocchi su cui deve essere eseguita la funzione mentre B rappresenta il numero di thread per ogni blocco.

\begin{lstlisting}[style=mycuda, caption=cuda kernels, captionpos=b]
//////////////////////////////////////CUDA Kernels/////////////////////////////////////

//resetta il valore di una variabile all'interno della scheda grafica
__global__ void CUDAresetVar(float *val) {
	*val = 0;
}

//applica ad ogni arco della rete la correzione del peso
__global__ void CUDAapplyWeightCorrections(float eps, float *NeuronOut, float *BPerr, float *weights, int *ArcIn, int *ArcOut, int nArcs) {
	unsigned int i = (blockIdx.x * blockDim.x) + threadIdx.x;
	if (i < nArcs) {
		weights[i] += -eps * BPerr[ArcIn[i]] * NeuronOut[ArcOut[i]];
	}
}

//applica le correzioni hai bayes dei neuroni
__global__ void CUDAapplyBayesCorrections(float eps, float *BPerr, float *Bayes, int startN, int endN) {
	unsigned int i = startN + (blockIdx.x * blockDim.x) + threadIdx.x;
	if (i <= endN) {
		Bayes[i] += -eps * BPerr[i];
	}
}

//retropropaga l'errore nella rete 
__global__ void CUDAPropagationErr(float *BPerr, float *weights, float *NeuronOut, int *ArcIn, int *ArcOut, int startA, int endA) {
	unsigned int i = startA + (blockIdx.x * blockDim.x) + threadIdx.x;

	//retropropago l'errore dai neuroni successivi
	if (i <= endA) {
		//BPerr[ArcOut[i]] += BPerr[ArcIn[i]] * weights[i];
		atomicAdd(&BPerr[ArcOut[i]], BPerr[ArcIn[i]] * weights[i]);
	}
}

//moltiplica l'errore delle uscite per la derivata puntuale della sigmoide
__global__ void CUDAoutDiff(float *BPerr, float *NeuronOut, int startN, int endN) {
	int i = startN + (blockIdx.x * blockDim.x) + threadIdx.x;
	if (i <= endN) {
		BPerr[i] *= NeuronOut[i] * (1 - NeuronOut[i]);
	}
}

//calcola l'errore dei neuroni dello strato output
__global__ void CUDAoutputErr(float *NeuronOut, int OutputRef, int numNeurons, int inputN, float *BPerr, float *examples, int exampleRef, float *mapMaxOut, float *mapMinOut, float *MeanErr) {

	unsigned int i = (OutputRef) + (blockIdx.x * blockDim.x) + threadIdx.x; //indice di scorrimento vettori: NeuronOut, BPerr, 
	unsigned int e = (exampleRef + inputN) + (blockIdx.x * blockDim.x) + threadIdx.x; //indice di scorrimento vettori: examples
	unsigned int m = (blockIdx.x * blockDim.x) + threadIdx.x; // indice di scorrimento vettori: mapMaxOut, mapMinOut
	//if (i == 0) *MeanErr = 0;
	if (i < numNeurons) {

		float delta = mapMaxOut[m] - mapMinOut[m];
		BPerr[i] = (NeuronOut[i] - ((examples[e] - mapMinOut[m]) / delta)) * NeuronOut[i] * (1 - NeuronOut[i]); // formula valida solo per i neuroni di uscita
		//atomicAdd(MeanErr, (abs((((NeuronOut[i] * delta) + mapMinOut[m]) - examples[e]) / examples[e]))*100.0f);
		atomicAdd(MeanErr, abs((((NeuronOut[i] * delta) + mapMinOut[m]) - examples[e])/ examples[e]) * 100.0f);
		// calcolo l'errore percentuale sulla singola uscita e lo sommo 
		//questo rappresenta uno dei punti più inefficienti dell'algoritmo, 
		//la funzione AtomicAdd infatti blocca la parallizazzione dell'algoritmo per tutti
		//i thread che cercheranno di accedere a tale variabile riportando solo per questi
		//l'esecuzione ad un modello sequenziale mettendoli in attesa
	}
}

//resetta un dato vettore 
__global__ void CUDAresetVector(float *vect, int size) {
	unsigned int i = (blockIdx.x * blockDim.x) + threadIdx.x;
	if (i < size) vect[i] = 0.0f;
}

//imposta i valori di output dei neuroni di input al valore dell'esempio del dataset
__global__ void CUDAsetInput(float *NeuronOut, int inputN, int exampleRef, float *example) {
	unsigned int i = (blockIdx.x * blockDim.x) + threadIdx.x;
	if (i < inputN)NeuronOut[i] = example[exampleRef + i];
}

//imposta i valori di output dei neuroni di input al valore specificato
__global__ void CUDAsetSingleInput(float *NeuronOut, int inputN, float *example) {
	unsigned int i = (blockIdx.x * blockDim.x) + threadIdx.x;
	if (i < inputN)NeuronOut[i] = example[i];
}

//applica la sigmoide ai potenziali dei neuroni in un dato intervallo (uno strato)
__global__ void CUDAsigLayer(float *NeuronOut, int start, int end) {
	unsigned int i = start + (blockIdx.x * blockDim.x) + threadIdx.x;
	if (i <= end) {
		NeuronOut[i] = 1 / (1 + expf(-NeuronOut[i]));
	}
}
//aggiunge all'output del neurone il contributo del bayes
__global__ void CUDAbayesInput(float *NeuronOut, float *Bayes, int start, int end) {
	unsigned int i = start + (blockIdx.x * blockDim.x) + threadIdx.x;
	if (i <= end) {
		NeuronOut[i] += Bayes[i];
	}
}

//propaga l'informazione dai neuroni dello strato input a quello di output
__global__ void CUDAlayerInput(float *weights, int *ArcIn, int *ArcOut, float *NeuronOut, int start, int end) {
	unsigned int i = start + (blockIdx.x * blockDim.x) + threadIdx.x;
	if (i <= end) {
		atomicAdd(&NeuronOut[ArcIn[i]], NeuronOut[ArcOut[i]] * weights[i]); 
		//addizione bloccante non permette ad altri thread di sovrascrivere il falore
		// finche l'operazione non è completata
	}
}

//////////////////////////////////////////////////////////////////////////////////////
\end{lstlisting}

Questa classe è l'interfaccia di collegamento con la GPU, la quale conserva i metodi di caricamento dei dati strutturali della rete, e gli esempi di addestramento sulla GPU.
\begin{lstlisting}[style=mycuda, caption= classe di interfaccia alla GPU, captionpos=b]
//api di interfacciamento alla GPU
class CUDAcore {
public:
	//Device specs struct (contiene le specifiche della GPU)
	cudaDeviceProp prop; 
	int GpuID = 0;

	//struttura contenente i puntatori alle aree di memoria conenenti i parametri della rete nella GPU
	struct devNetParams {
		float *weights = 0;
		int *ArcIn = 0;
		int *ArcOut = 0;
		float *examples = 0;
		float *NeuronOut = 0;
		float *Bayes = 0;
		float *BPerr = 0;
		float *mapMaxOut = 0;
		float *mapMinOut = 0;
		int *NeurInLyr = 0;
		int *priority = 0;
		float *MeanErr = 0;
		float *InputRT = 0;
	}gpuNetParams;

	vector<float> weights; //pesi della rete
	vector<int> ArcIn; //target dell'n-esimo arco
	vector<int> ArcOut; //base dell'n-esimo arco
	vector<float> NeuronOut; //vettore contenente l'output dei neuroni
	vector<float> Bayes; //vettore contenente i bayes dei neuroni
	vector<float> BPerr; // vettore contenete gli errori retropropagati
	vector<float> mapMaxOut; //vettore contenente il massimo valore degli output
	vector<float> mapMinOut; //vettore contenente il minimo valore degli output
	vector<int> priority; // vettore contenente i punti di sincronizazione dei thread
	vector<int> NeurInLyr; //vettore contenente gli indici dell'ultimo neurone di ogni layer
	vector<float>examples; //vettore degli esempi
	float MeanErr = 0; //veriabile contenente l'errore medio percentuale della rete
	int inputN, outputN; //passo di esecuzione elementi del vettore esempi

	CUDAcore(int nGpu) {
		GpuID = nGpu;
		checkCuda(cudaGetDeviceProperties(&prop, nGpu)); // carica lo struct cudaDeviceProp prop con le caratteristiche della GPU con indice 0
	}
	
\end{lstlisting}

La seguenti funzioni interne della classe di interfaccia alla GPU, rappresentano il metodo di conversione della struttura della rete dalla classe MLP alla classe CudaCore, e viceversa, tale conversione porta il modello da una struttura reticolare a puntatori in una struttura a vettori lineare.\\
Tale struttura divide i vari parametri della rete in vettori lineari, ogni tipo di elemento viene raggruppato in un unico vettore, mentre le connessioni precedentemente rappresentate da puntatori divengono vettori a loro volta che fungono da tabelle di accesso ordinate, scorrendo dal primo elemento all'ultimo si trovano tutti gli elementi su cui eseguire sequenzialmente le operazioni da svolgere per eseguire la propagazione. La complessità di tale operazione sta proprio nello svolgimento della struttura della rete per poter eseguire con efficienza la computazione sulla scheda grafica, la quale deve essere più "machine-friendly" possibile, data l'enorme quantità di operazioni che deve essere svolta per eseguire l'addestramento. 
Sono indicate anche altre funzioni di conversione per Hopfield e per il dataset il quale ha bisogno anch'esso di serializzazione per l'utilizzo nelle successive funzioni.

\begin{lstlisting}[style=mycuda, caption= classe di interfaccia alla GPU, captionpos=b]
	//copia del modello da MLP class a CudaCore class
	void cudaNetCopyMLP(MLP *pt) {
		cout << "copying the net into CUDAcore.." << endl;
		weights.resize(pt->nArc);
		ArcIn.resize(pt->nArc);
		ArcOut.resize(pt->nArc);
		NeuronOut.resize(pt->nNeurons);
		Bayes.resize(pt->nNeurons);
		BPerr.resize(pt->nNeurons);
		priority.resize(pt->nLayers + 1);
		NeurInLyr.resize(pt->nLayers + 1);
		mapMaxOut.resize(pt->map.size());
		mapMinOut.resize(pt->map.size());
		inputN = pt->numNeurons(0);
		outputN = pt->numNeurons(pt->nLayers - 1);

		int NeuronIdx = 0;
		int ArcIdx = 0;
		vector<int> neurons(pt->nLayers);
		//carico il vettore di mappatura dell'output della rete
		for (int i = 0; i < pt->map.size(); i++) {
			mapMaxOut[i] = pt->map[i].maxValue;
			mapMinOut[i] = pt->map[i].minValue;
		}

		NeurInLyr[0] = -1; // setto il primo valore 
		priority[0] = -1; // setto il primo valore 

		//carico i parametri della rete
		for (int i = 0; i < pt->nLayers; i++) {

			for (int j = 0; j < pt->numNeurons(i); j++) {

				Bayes[NeuronIdx] = pt->getTarget(i, j)->bayes;

				for (int k = 0; k < pt->numCon(i, j); k++) {

					weights[ArcIdx] = pt->getTarget(i, j)->OutArcs[k].weight;
					ArcIn[ArcIdx] = pt->getTarget(i, j)->OutArcs[k].target->neurIdx;
					ArcOut[ArcIdx] = pt->getTarget(i, j)->neurIdx;
					ArcIdx++;
				}
				NeuronIdx++;
			}
			NeurInLyr[i + 1] = NeuronIdx - 1; // salvo l'indice dell'ultimo neurone del layer corrente
			priority[i + 1] = ArcIdx - 1; // salvo l'indice dell'ultimo arco del layer corrente
		}
	}
	
	//copia del modello da CudaCore class a MLP class
	void cudaNetPasteMLP(MLP *pt) {
		int idx = 0;
		int Nidx = 0;
		for (int i = 0; i < pt->nLayers; i++) {
			for (int j = 0; j < pt->numNeurons(i); j++) {
				pt->getTarget(i, j)->bayes = Bayes[Nidx++];
				for (int k = 0; k < pt->numCon(i, j); k++) {
					pt->getTarget(i, j)->OutArcs[k].weight = weights[idx++];
				}
			}
		}
	}

	void cudaNetCopyHopfield(Hopfield* pt) { ... }

	void cudaNetCopyExamples(MLP *pt) { ... }
	
\end{lstlisting}

\subsubsection{metodi che lanciano i kernel sulla GPU}
i seguenti metodi interagiscono direttamente con la GPU allocando memoria su di essa, caricando i dati, e lanciando i kernel che eseguono le effettive operazioni sulla GPU.  

\begin{lstlisting}[style=mycuda, caption= classe di interfaccia alla GPU, captionpos=b]
	
	///////////////////////////////CUDA Kernel functions//////////////////////////
	//esegue le operazioni di allocamento memoria e preparazione al lancio del kernel di propagazione della rete
	cudaError_t hostCUDAtrainingNet(float eps, int Niter, int ThxBlock) {
		cout << "learning is started!" << endl;
		//host variables
		float *Cweights = &weights[0];
		int *CArcIn = &ArcIn[0];
		int *CArcOut = &ArcOut[0];
		float *CNeuronOut = &NeuronOut[0];
		float *CBayes = &Bayes[0];
		float *CBPerr = &BPerr[0];
		float *CmapMaxOut = &mapMaxOut[0];
		float *CmapMinOut = &mapMinOut[0];
		float *Cexamples = &examples[0];
		int *CNeurInLyr = &NeurInLyr[0];
		int *Cpriority = &priority[0];
		float *CMeanErr = &MeanErr;

		//device variables
		float *dev_weights = 0;
		int *dev_ArcIn = 0;
		int *dev_ArcOut = 0;
		float *dev_examples = 0;
		float *dev_NeuronOut = 0;
		float *dev_Bayes = 0;
		float *dev_BPerr = 0;
		float *dev_mapMaxOut = 0;
		float *dev_mapMinOut = 0;
		int *dev_NeurInLyr = 0;
		int *dev_priority = 0;
		float *dev_MeanErr = 0;

		//int ThxBlock = 1024;

		cudaError_t cudaStatus;

		// Choose which GPU to run on, change this on a multi-GPU system.
		cudaStatus = cudaSetDevice(GpuID);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;

		// Allocate GPU buffers for vectors    
		cudaStatus = cudaMalloc((void**)&dev_weights, weights.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_ArcIn, ArcIn.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_ArcOut, ArcOut.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_NeuronOut, NeuronOut.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_Bayes, Bayes.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_BPerr, BPerr.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_mapMaxOut, mapMaxOut.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_mapMinOut, mapMinOut.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_examples, examples.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_NeurInLyr, NeurInLyr.size() * sizeof(int));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_priority, priority.size() * sizeof(int));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&dev_MeanErr, sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;


		// Copy input vectors from host memory to GPU buffers.
		cudaStatus = cudaMemcpy(dev_weights, Cweights, weights.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_ArcIn, CArcIn, ArcIn.size() * sizeof(int), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_ArcOut, CArcOut, ArcOut.size() * sizeof(int), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_NeuronOut, CNeuronOut, NeuronOut.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_Bayes, CBayes, Bayes.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_BPerr, CBPerr, BPerr.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_mapMaxOut, CmapMaxOut, mapMaxOut.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_mapMinOut, CmapMinOut, mapMinOut.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_examples, Cexamples, examples.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_NeurInLyr, CNeurInLyr, NeurInLyr.size() * sizeof(int), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_priority, Cpriority, priority.size() * sizeof(int), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(dev_MeanErr, CMeanErr, sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;



		//////////////////lancio dei kernel all'interno della gpu////////////////
		int startA = 0;
		int endA = 0;
		int startN = 0;
		int endN = 0;
		int numLayerArcs = 0;
		int numLayerNeur = 0;
		int numOfBlocksMax = 0;
		int numOfBlocksA = 0;
		int numOfBlocksN = 0;
		int numOfBlocksOut = floorf(outputN / ThxBlock) + 1;
		int exampleRef = 0;
		int outputRef = NeuronOut.size() - outputN;
		long long t0 = 0, t1 = 0;
		long long t0in = 0, t1in = 0;
		double elapsedMilliseconds = 0;
		double elapsedInMilliseconds = 0;

		for (int it = 0; it < Niter; it++) { //scorro le iterazioni

			t0 = PerformanceCounter();

			for (int t = 0; t < (examples.size() / (inputN + outputN)); t++) { //scorro gli esempi
				//imposto il riferimento per l'esempio di input
				exampleRef = t * (inputN + outputN);
				t0in = PerformanceCounter();
				//resetto il vettore contenente lo stato di attivazione dei neuroni
				numOfBlocksA = (floorf(NeuronOut.size() / ThxBlock) + 1);
				CUDAresetVector <<<numOfBlocksA, ThxBlock >>> (dev_NeuronOut, NeuronOut.size());

				//imposto i valori di input ai neuroni dello strato input
				numOfBlocksA = (floorf(inputN / ThxBlock) + 1);
				CUDAsetInput <<<numOfBlocksA, ThxBlock >>> (dev_NeuronOut, inputN, exampleRef, dev_examples);

				//propagazione dell'input nella rete

				startA = 0; // indice di partenza dei vettori archi
				endA = 0; // ultimo indice dei vettori archi
				startN = 0; // indice di partenza dei vettori neuroni
				endN = 0; // ultimo indice dei vettori neuroni

				for (int i = 0; i < priority.size() - 1; i++) { //NB non viene applicata la sigmoide allo strato di input eventulmente correggi

					startA = priority[i] + 1;
					endA = priority[i + 1];

					if (i < priority.size() - 2) {
						startN = NeurInLyr[i + 1] + 1;
						endN = NeurInLyr[i + 2];
					}

					numLayerArcs = endA - startA + 1;
					numLayerNeur = endN - startN + 1;

					numOfBlocksA = floorf(numLayerArcs / ThxBlock) + 1;
					numOfBlocksN = floorf(numLayerNeur / ThxBlock) + 1;

					if (i < priority.size() - 2) {
						//propago l'output dei neuroni al prossimo/i layer
						CUDAlayerInput <<<numOfBlocksA, ThxBlock >>> (dev_weights, dev_ArcIn, dev_ArcOut, dev_NeuronOut, startA, endA); 
						 //applico il contributo dei bayes all output dei neuroni del layer corrente 
						CUDAbayesInput <<< numOfBlocksN, ThxBlock >>> (dev_NeuronOut, dev_Bayes, startN, endN);
						//applico la sigmoide allo stato di attivazione dei neuroni
						CUDAsigLayer <<<numOfBlocksN, ThxBlock >>> (dev_NeuronOut, startN, endN); 
					}
				}

				t1in = PerformanceCounter();
				elapsedInMilliseconds += ((t1in - t0in) * 1000.0) / PerformanceFrequency();


				//resetto il vettore contenente l'errore  dei neuroni
				numOfBlocksN = (floorf(BPerr.size() / ThxBlock) + 1);
				CUDAresetVector <<<numOfBlocksN, ThxBlock >>> (dev_BPerr, BPerr.size());

				CUDAresetVar <<<1, 1 >>> (dev_MeanErr);
				CUDAoutputErr <<<numOfBlocksOut, ThxBlock >>> (dev_NeuronOut, outputRef, NeuronOut.size(), inputN, dev_BPerr, dev_examples, exampleRef, dev_mapMaxOut, dev_mapMinOut, dev_MeanErr);
				cudaMemcpy(CMeanErr, dev_MeanErr, sizeof(float), cudaMemcpyDeviceToHost);

				MeanErr += *CMeanErr / outputN;


				//retropropagazione dell'errore

				for (int i = priority.size() - 2; i > 1; i--) {

					startA = priority[i - 1] + 1;
					endA = priority[i];
					startN = NeurInLyr[i - 1] + 1;
					endN = NeurInLyr[i];

					numLayerArcs = endA - startA + 1;
					numLayerNeur = endN - startN + 1;

					numOfBlocksA = floorf(numLayerArcs / ThxBlock) + 1;
					numOfBlocksN = floorf(numLayerNeur / ThxBlock) + 1;
					//numOfBlocksMax = maxOf(numOfBlocksA, numOfBlocksN);

					CUDAPropagationErr <<<numOfBlocksA, ThxBlock >>> (dev_BPerr, dev_weights, dev_NeuronOut, dev_ArcIn, dev_ArcOut, startA, endA);
					CUDAoutDiff <<<numOfBlocksN, ThxBlock >>> (dev_BPerr, dev_NeuronOut, startN, endN);
					cudaStatus = cudaMemcpy(CBPerr, dev_BPerr, BPerr.size() * sizeof(float), cudaMemcpyDeviceToHost);
					if (cudaCheckStatus(cudaStatus) == true) goto Error;
					copy(CBPerr, CBPerr + BPerr.size(), BPerr.begin());
				}

				//applico a ogni peso la sua correzione

				startN = NeurInLyr[1] + 1; // la correzione dei bais va applicata dal primo layer nascosto in poi
				endN = NeurInLyr[NeurInLyr.size() - 1];

				numLayerNeur = endN - startN + 1;

				numOfBlocksA = floorf(weights.size() / ThxBlock) + 1;
				numOfBlocksN = floorf(numLayerNeur / ThxBlock) + 1;

				CUDAapplyWeightCorrections <<<numOfBlocksA, ThxBlock >>> (eps, dev_NeuronOut, dev_BPerr, dev_weights, dev_ArcIn, dev_ArcOut, weights.size());
				CUDAapplyBayesCorrections <<<numOfBlocksN, ThxBlock >>> (eps, dev_BPerr, dev_Bayes, startN, endN);
			}

			t1 = PerformanceCounter();
			elapsedMilliseconds = ((t1 - t0) * 1000.0) / PerformanceFrequency(); // calcolo il tempo di esecuzione di una iterazione di addestramento (tutto il set)
			MeanErr = MeanErr / (examples.size() / (inputN + outputN)); //calcolo l'errore percentuale medio sul dataset
			elapsedInMilliseconds = elapsedInMilliseconds / (examples.size() / (inputN + outputN));
			cout << "Iterazione: " << it << "  " << MeanErr << " %Err  " << "execution time:" << elapsedMilliseconds << "ms" << endl;
			cout << "mean InputTime: " << elapsedInMilliseconds << "ms" << endl;
			printNetSpecs();
			MeanErr = 0;
		}

		cudaStatus = cudaMemcpy(Cweights, dev_weights, weights.size() * sizeof(float), cudaMemcpyDeviceToHost);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		copy(Cweights, Cweights + weights.size(), weights.begin());

		cudaStatus = cudaMemcpy(CBayes, dev_Bayes, Bayes.size() * sizeof(float), cudaMemcpyDeviceToHost);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		copy(CBayes, CBayes + Bayes.size(), Bayes.begin());
		//checkpoint di errore (se la GPU richiama un qualunque errore ripare da qui)
	Error:

		//libero la memoria nella scheda grafica
		cudaFree(dev_weights);
		cudaFree(dev_ArcIn);
		cudaFree(dev_ArcOut);
		cudaFree(dev_NeuronOut);
		cudaFree(dev_examples);
		cudaFree(dev_BPerr);
		cudaFree(dev_mapMaxOut);
		cudaFree(dev_mapMinOut);
		cudaFree(dev_priority);
		cudaFree(dev_NeurInLyr);

		//ritorno lo stato della GPU
		return cudaStatus;
	}

	//esegue il caricamento nella gpu dei parametri della rete
	cudaError_t hostCUDAuploadNetParams() {

		cudaError_t cudaStatus;

		cudaStatus = cudaSetDevice(GpuID);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;

		//host variables
		float *Cweights = &weights[0];
		int *CArcIn = &ArcIn[0];
		int *CArcOut = &ArcOut[0];
		float *CNeuronOut = &NeuronOut[0];
		float *CBayes = &Bayes[0];
		float *CBPerr = &BPerr[0];
		float *CmapMaxOut = &mapMaxOut[0];
		float *CmapMinOut = &mapMinOut[0];
		float *Cexamples = &examples[0];
		int *CNeurInLyr = &NeurInLyr[0];
		int *Cpriority = &priority[0];
		float *CMeanErr = &MeanErr;

		// Choose which GPU to run on, change this on a multi-GPU system.
		cudaStatus = cudaSetDevice(GpuID);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;

		// Allocate GPU buffers for vectors    
		cudaStatus = cudaMalloc((void**)&gpuNetParams.weights, weights.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.ArcIn, ArcIn.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.ArcOut, ArcOut.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.NeuronOut, NeuronOut.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.Bayes, Bayes.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.BPerr, BPerr.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.mapMaxOut, mapMaxOut.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.mapMinOut, mapMinOut.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.examples, examples.size() * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.NeurInLyr, NeurInLyr.size() * sizeof(int));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.priority, priority.size() * sizeof(int));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.InputRT, inputN * sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMalloc((void**)&gpuNetParams.MeanErr, sizeof(float));
		if (cudaCheckStatus(cudaStatus) == true) goto Error;


		// Copy input vectors from host memory to GPU buffers.
		cudaStatus = cudaMemcpy(gpuNetParams.weights, Cweights, weights.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.ArcIn, CArcIn, ArcIn.size() * sizeof(int), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.ArcOut, CArcOut, ArcOut.size() * sizeof(int), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.NeuronOut, CNeuronOut, NeuronOut.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.Bayes, CBayes, Bayes.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.BPerr, CBPerr, BPerr.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.mapMaxOut, CmapMaxOut, mapMaxOut.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.mapMinOut, CmapMinOut, mapMinOut.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.examples, Cexamples, examples.size() * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.NeurInLyr, CNeurInLyr, NeurInLyr.size() * sizeof(int), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.priority, Cpriority, priority.size() * sizeof(int), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
		cudaStatus = cudaMemcpy(gpuNetParams.MeanErr, CMeanErr, sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;

		if (false) {
			Error:
			//libero la memoria nella scheda grafica
			cudaFree(gpuNetParams.weights);
			cudaFree(gpuNetParams.ArcIn);
			cudaFree(gpuNetParams.ArcOut);
			cudaFree(gpuNetParams.NeuronOut);
			cudaFree(gpuNetParams.examples);
			cudaFree(gpuNetParams.BPerr);
			cudaFree(gpuNetParams.mapMaxOut);
			cudaFree(gpuNetParams.mapMinOut);
			cudaFree(gpuNetParams.priority);
			cudaFree(gpuNetParams.NeurInLyr);
			cout << "ERRORE: libero la memoria della gpu. " << endl;
		}
			
		return cudaStatus;
	}

	//esegue il download dalla gpu dei parametri della rete
	cudaError_t hostCUDAdownloadNetParams() {

		cout << "downloading net params from gpu.." << endl;

		float *Cweights = &weights[0];
		float *CBayes = &Bayes[0];

		cudaError_t cudaStatus;

		cudaStatus = cudaSetDevice(GpuID);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;

		cudaStatus = cudaMemcpy(Cweights, gpuNetParams.weights, weights.size() * sizeof(float), cudaMemcpyDeviceToHost);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;

		cudaStatus = cudaMemcpy(CBayes, gpuNetParams.Bayes, Bayes.size() * sizeof(float), cudaMemcpyDeviceToHost);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;


		if (false) {
		Error:
			//libero la memoria nella scheda grafica
			cudaFree(gpuNetParams.weights);
			cudaFree(gpuNetParams.ArcIn);
			cudaFree(gpuNetParams.ArcOut);
			cudaFree(gpuNetParams.NeuronOut);
			cudaFree(gpuNetParams.examples);
			cudaFree(gpuNetParams.BPerr);
			cudaFree(gpuNetParams.mapMaxOut);
			cudaFree(gpuNetParams.mapMinOut);
			cudaFree(gpuNetParams.priority);
			cudaFree(gpuNetParams.NeurInLyr);
			cout << "ERRORE: libero la memoria della gpu. " << endl;
		}

		return cudaStatus;
	}

	//esegue l'input della rete gia addestrata prendendo in input l'esempio dato 
	cudaError_t hostCUDAInputNet(float *input, int ThxBlock) {
		//inportante verificare che l'input abbia la stessa dimansione dell'input della rete

		cudaError cudaStatus;

		cudaStatus = cudaSetDevice(GpuID);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;

		//////////////////lancio dei kernel all'interno della gpu////////////////
		//int ThxBlock = 1024;
		int startA = 0;
		int endA = 0;
		int startN = 0;
		int endN = 0;
		int numLayerArcs = 0;
		int numLayerNeur = 0;
		int numOfBlocksMax = 0;
		int numOfBlocksA = 0;
		int numOfBlocksN = 0;
		int numOfBlocksOut = floorf(outputN / ThxBlock) + 1;
		int outputRef = NeuronOut.size() - outputN;
		long long t0in = 0, t1in = 0;
		double elapsedInMilliseconds = 0;
			
		t0in = PerformanceCounter();
		//resetto il vettore contenente lo stato di attivazione dei neuroni
		numOfBlocksA = (floorf(NeuronOut.size() / ThxBlock) + 1);
		CUDAresetVector <<<numOfBlocksA, ThxBlock >>> (gpuNetParams.NeuronOut, NeuronOut.size());

		cudaStatus = cudaMemcpy(gpuNetParams.InputRT, input, inputN * sizeof(float), cudaMemcpyHostToDevice);
		if (cudaCheckStatus(cudaStatus) == true) goto Error;

		//imposto i valori di input ai neuroni dello strato input
		numOfBlocksA = (floorf(inputN / ThxBlock) + 1);
		CUDAsetSingleInput <<<numOfBlocksA, ThxBlock>>> (gpuNetParams.NeuronOut, inputN, gpuNetParams.InputRT);
		
		//propagazione dell'input nella rete

		startA = 0; // indice di partenza dei vettori archi
		endA = 0; // ultimo indice dei vettori archi
		startN = 0; // indice di partenza dei vettori neuroni
		endN = 0; // ultimo indice dei vettori neuroni

		for (int i = 0; i < priority.size() - 1; i++) { //NB non viene applicata la sigmoide allo strato di input eventulmente correggi

			startA = priority[i] + 1;
			endA = priority[i + 1];

			if (i < priority.size() - 2) {
				startN = NeurInLyr[i + 1] + 1;
				endN = NeurInLyr[i + 2];
			}

			numLayerArcs = endA - startA + 1;
			numLayerNeur = endN - startN + 1;

			numOfBlocksA = floorf(numLayerArcs / ThxBlock) + 1;
			numOfBlocksN = floorf(numLayerNeur / ThxBlock) + 1;

			if (i < priority.size() - 2) {
				CUDAlayerInput <<<numOfBlocksA, ThxBlock >>> (gpuNetParams.weights, gpuNetParams.ArcIn, gpuNetParams.ArcOut, gpuNetParams.NeuronOut, startA, endA); //propago l'output dei neuroni al prossimo/i layer
				CUDAbayesInput <<<numOfBlocksN, ThxBlock >>> (gpuNetParams.NeuronOut, gpuNetParams.Bayes, startN, endN); //applico il contributo dei bayes all output dei neuroni del layer corrente 
				CUDAsigLayer <<<numOfBlocksN, ThxBlock >>> (gpuNetParams.NeuronOut, startN, endN); //applico la sigmoide allo stato di attivazione dei neuroni
				
			}
		}

		//copio l'output dei neuroni dello strato output nella memoria della cpu
		cudaStatus = cudaMemcpy(&NeuronOut[0] + outputRef, gpuNetParams.NeuronOut + outputRef, outputN * sizeof(float), cudaMemcpyDeviceToHost); //TODO da errore e non carica il vettore trovare il BUG
		if (cudaCheckStatus(cudaStatus) == true) goto Error;
			
		t1in = PerformanceCounter();
		elapsedInMilliseconds = ((t1in - t0in) * 1000.0) / PerformanceFrequency();

		///////////////////////////visualizzazione dell'esempio//////////////////////////////

		float delta;
		cout << "input time: " << elapsedInMilliseconds << " ms" << endl;

		for (int on = 0; on < outputN; on++) {
			delta = mapMaxOut[on] - mapMinOut[on];
			cout << "Y" << on << ": " << (NeuronOut[NeuronOut.size() - outputN + on] * delta) + mapMinOut[on] << endl;
		}
		cout << endl;
		
		//////////////////////////////////////////////////////////////////////////////////////

		if (false) {
		Error:
			//libero la memoria nella scheda grafica
			cudaFree(gpuNetParams.weights);
			cudaFree(gpuNetParams.ArcIn);
			cudaFree(gpuNetParams.ArcOut);
			cudaFree(gpuNetParams.NeuronOut);
			cudaFree(gpuNetParams.examples);
			cudaFree(gpuNetParams.BPerr);
			cudaFree(gpuNetParams.mapMaxOut);
			cudaFree(gpuNetParams.mapMinOut);
			cudaFree(gpuNetParams.priority);
			cudaFree(gpuNetParams.NeurInLyr);
		}

		return cudaStatus;
	}
	//////////////////////////////////////////////////////////////////////////////////////
	
	////////////////////////////////CUDA UTILITY//////////////////////////////////////////
	//verifica la corretta esecuzione di un operazione
	inline cudaError_t checkCuda(cudaError_t result){ ... }
	
	//verifica la corretta esecuzione di un operazione restituendo un bool
	bool cudaCheckStatus(cudaError_t cudaStatus) { ... }
	
	//stampa a schermo le principali proprietà della scheda
	void printDeviceSpecs() { ... }
	
	//stampa i parametri della rete che vengono passati alla scheda
	void printNetSpecs() { ... }
	
	//calcola il peso del modello
	float sizeOfModel(string mesureUnit = "B") { ... }
	
	template<typename T, typename A>
	float sizeOfVector(vector<T, A> const& vect,string mesureUnit = "B") { ... }
	//////////////////////////////////////////////////////////////////////////////////////
};

\end{lstlisting}

\end{document}
























